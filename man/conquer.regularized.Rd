% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/smqr.R
\name{conquer.regularized}
\alias{conquer.regularized}
\title{Convolution-Type Smoothed Quantile Regression with Lasso, Scad and Mcp Penalties}
\usage{
conquer.regularized(
  X,
  Y,
  lambda = 0.2,
  tau = 0.5,
  kernel = c("Gaussian", "logistic", "uniform", "parabolic", "triangular"),
  h = 0,
  penalty = c("lasso", "scad", "mcp"),
  para = NULL,
  epsilon = 0.001,
  iteMax = 500,
  phi0 = 0.01,
  gamma = 1.2,
  iteTight = 3
)
}
\arguments{
\item{X}{A \eqn{n} by \eqn{p} design matrix. Each row is a vector of observation with \eqn{p} covariates.}

\item{Y}{An \eqn{n}-dimensional response vector.}

\item{lambda}{(\strong{optional}) A prescribed value for the regularization parameter. Default is 0.2.}

\item{tau}{(\strong{optional}) The desired quantile level. Default is 0.5. Value must be between 0 and 1.}

\item{kernel}{(\strong{optional}) A character string specifying the choice of kernel function. Default is "Gaussian". Choices are "Gaussian", "logistic", "uniform", "parabolic" or "triangular".}

\item{h}{(\strong{optional}) The bandwidth parameter for kernel smoothing. Default is \eqn{max(0.5 * (log(p) / n)^(1/4), 0.05)}.}

\item{penalty}{(\strong{optional}) A character string specifying the penalty. Default is "lasso". Choices are "lasso", "scad" or "mcp".}

\item{para}{(\strong{optional}) A parameter for concave penalties scad and mcp. Do not need to specify if the penalty is lasso. The default values are 3.7 for scand and 3 for mcp.}

\item{epsilon}{(\strong{optional}) A tolerance level for the optimization stopping rule. The algorithm terminates when the maximal entry of the change of coefficients is less than \code{epsilon}. Default is 0.001.}

\item{iteMax}{(\strong{optional}) Maximum number of iterations. Default is 500.}

\item{phi0}{(\strong{optional}) A parameter for the local majorize-minimize algorithm. It is the initial value to search the largest eigen value of the covariance matrix. Default is 0.01.}

\item{gamma}{(\strong{optional}) A parameter for the local majorize-minimize algorithm. It is the inflating parameter to search the largest eigen value of the covariance matrix. Default is 1.2.}

\item{iteTight}{(\strong{optional}) Maximum number of tightening iterations. Do not need to specify if the penalty is lasso. Default is 3.}
}
\value{
An object containing the following items will be returned:
\describe{
\item{\code{coeff}}{A \eqn{(p + 1)} vector of estimated coefficients, including the intercept.}
\item{\code{bandwidth}}{The value of smoothing bandwidth.}
\item{\code{tau}}{The desired quantile level for the regularized regression.}
\item{\code{kernel}}{The choice of kernel function.}
\item{\code{penalty}}{The choice of penalty type.}
\item{\code{lambda}}{The value of regularization parameter.}
\item{\code{n}}{The sample size.}
\item{\code{p}}{The dimension of the covariates.}
}
}
\description{
Fit a smoothed quantile regression with Lasso, scad and mcp penalties and a prescribed regularization parameter \eqn{lambda} using a local majorize-minimize algorithm.
}
\references{
Fan, J., Liu, H., Sun, Q. and Zhang, T. (2018). I-LAMM for sparse learning: Simultaneous control of algorithmic complexity and statistical error. Ann. Statist. 46 814-841.

Koenker, R. and Bassett, G. (1978). Regression quantiles. Econometrica 46 33-50.

Tan, K. M., Wang, L. and Zhou, W.-X. (2021). High-dimensional quantile regression: convolution smoothing and concave regularization. Preprint.
}
\seealso{
See \code{\link{conquer.cv.regularized}} for regularized quantile regression with cross-validation.
}
\author{
Xuming He <xmhe@umich.edu>, Xiaoou Pan <xip024@ucsd.edu>, Kean Ming Tan <keanming@umich.edu>, and Wen-Xin Zhou <wez243@ucsd.edu>
}
